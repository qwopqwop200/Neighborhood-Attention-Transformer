# Neighborhood-Attention-Transformer
NAT implementation(Neighborhood Attention Transformer)

This is an unofficial implementation. https://arxiv.org/pdf/2204.07143.pdf

original implemented:https://github.com/SHI-Labs/Neighborhood-Attention-Transformer

This is a pytorch implementation and cuda(use cupy) implementation. As mentioned in the paper, it may be slower than the original implemented in cuda.
